# ===================================================================
# Spring Boot configuration.
#
# This configuration will be overridden by the Spring profile you use,
# for example application-dev.yml if you use the "dev" profile.
#
# Full reference for Standard Spring Boot properties is available at:
# http://docs.spring.io/spring-boot/docs/current/reference/html/common-application-properties.html
# ===================================================================
# set -Dspring.profiles.active=<dev|sit|int> as JVM argument to run in desired profile
# If no profile is specified explicitly, application will fall back to default profile, which is "local"

spring:
  application:
    name: spring-boot-spark-iceberg
  profiles:
    include: ${CATALOG_TYPE:none}-catalog
  docker:
    compose:
      enabled: false
#  autoconfigure:
#    exclude: org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration
  devtools:
    add-properties: false
    restart:
      enabled: false
      exclude: logs/*,application.log,*.log,*.log.*
  main:
    log-startup-info: true
  messages:
    basename: messages,i18n/problems
    cache-duration: PT10S # 10 second, see the ISO 8601 standard
    fallback-to-system-locale: true
    always-use-message-format: false
    use-code-as-default-message: false
  mvc:
    pathmatch:
      matching-strategy: ant-path-matcher
    problemdetails:
      enabled: false
  threads:
    virtual:
      enabled: true

  jackson:
    serialization:
      write-dates-as-timestamps: false

#  cloud:
#    aws:
#      credentials:
#        access-key: ${AWS_ACCESS_KEY:}
#        secret-key: ${AWS_SECRET_KEY:}
#      region:
#        static: ${AWS_REGION:ap-south-1}
#      s3:
#        endpoint: ${AWS_S3_ENDPOINT:https://s3.ap-south-1.amazonaws.com}

#------------------------- Swagger configuration -------------------------
springdoc:
  show-actuator: true
  swagger-ui:
    syntaxHighlight:
      activated: true

# ------------------------ Problem configurations  ------------------------
problem:
  type-url: http://localhost:${server.port}/problems/help.html
  enabled: true
  debug-enabled: false
  stacktrace-enabled: false
  cause-chains-enabled: false

server:
  port: 8090
  forward-headers-strategy: framework
#  servlet:
#      context-path:
logging:
  level:
    ROOT: info
#    '[org.mongodb.driver]': warn
debug: false

# ===================================================================
# Application specific properties
# Add your own application properties here
# ===================================================================

#------------------------- Spark configurations -------------------------
spark:
  master: local
  app.name: ${spring.application.name}
  local.dir: spark-space/tmp
  driver:
    memory: 4g
    cores: 4
  executor:
    instances: 4
    memory: 2g
    cores: 2
  ui:
    enabled: false
  default:
    parallelism: 32
  sql:
    datetime.java8API.enabled: true
    session.timeZone: "+05:30"
#  hadoop:
#    fs:
#      s3a:
#        aws.credentials.provider: "org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider"
#        access.key: ${AWS_ACCESS_KEY:}
#        secret.key: ${AWS_SECRET_KEY:}
#        endpoint: ${AWS_S3_ENDPOINT:s3.ap-south-1.amazonaws.com}
#        impl: org.apache.hadoop.fs.s3a.S3AFileSystem
#        path.style.access: true  # For path-style access, useful in some S3-compatible services
#        connection.ssl.enabled: false  # Enable SSL
#        fast.upload: true  # Enable faster uploads


#----------------- Iceberg Catalog configurations ----------------
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
#  Add VM Argument -DCATALOG_TYPE=hadoop to activate this profile  #
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
---
spring.config.activate.on-profile: hadoop-catalog
#----------------- Hadoop Iceberg Catalog configurations ----------------
spark:
  sql:
    catalog:
      hadoop: org.apache.iceberg.spark.SparkCatalog
      hadoop.type: hadoop
      hadoop.warehouse: ${CATALOG_WAREHOUSE:hdfs://localhost:9000/warehouse}
      hadoop.uri: ${CATALOG_URI:hdfs://localhost:9000}
      hadoop.default-namespace: ${CATALOG_NAMESPACE:ksoot}
      hadoop.io-impl: org.apache.iceberg.hadoop.HadoopFileIO

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
#  Add VM Argument -DCATALOG_TYPE=hive to activate this profile  #
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
---
spring.config.activate.on-profile: hive-catalog
#---------------- Hive Iceberg Catalog configurations ----------------
spark:
  sql:
    catalog:
      hive: org.apache.iceberg.spark.SparkCatalog
      hive.type: hive
      hive.warehouse: ${CATALOG_WAREHOUSE:/user/hive/warehouse}
      #      hive.warehouse: ${CATALOG_WAREHOUSE:s3a://my-iceberg-bucket}
      hive.uri: ${CATALOG_URI:thrift://localhost:9083}
      hive.default-namespace: ${CATALOG_NAMESPACE:ksoot}
      hive.io-impl: org.apache.iceberg.hadoop.HadoopFileIO
#      hive.io-impl: org.apache.iceberg.aws.s3.S3FileIO
#      hive.hadoop.access.key: ${AWS_ACCESS_KEY:}
#      hive.hadoop.fs.s3a.secret.key: ${AWS_SECRET_KEY:}
#      hive.hadoop.fs.s3a.endpoint: ${AWS_S3_ENDPOINT:s3.ap-south-1.amazonaws.com}
#      hive.hadoop.fs.s3a.impl: org.apache.hadoop.fs.s3a.S3AFileSystem
#      hive.hadoop.fs.s3a.path.style.access: true  # For path-style access, useful in some S3-compatible services
#      hive.hadoop.fs.s3a.connection.ssl.enabled: false  # Enable SSL
#      hive.hadoop.fs.s3a.fast.upload: true  # Enable faster uploads

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
#  Add VM Argument -DCATALOG_TYPE=nessie to activate this profile  #
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
---
spring.config.activate.on-profile: nessie-catalog
#---------------- Nessie Iceberg Catalog configurations ----------------
spark:
  sql:
    catalog:
      nessie: org.apache.iceberg.spark.SparkCatalog
      nessie.type: nessie
#      nessie.warehouse: ${CATALOG_WAREHOUSE:s3a://my-iceberg-bucket}
      nessie.warehouse: ${CATALOG_WAREHOUSE:hdfs://localhost:9000/warehouse}
      nessie.uri: ${CATALOG_URI:http://localhost:19120/api/v2}
      nessie.default-namespace: ${CATALOG_NAMESPACE:ksoot}
      #      nessie.ref: "main"
      nessie.io-impl: org.apache.iceberg.hadoop.HadoopFileIO
#      nessie.io-impl: org.apache.iceberg.aws.s3.S3FileIO
#      nessie.hadoop.access.key: ${AWS_ACCESS_KEY:}
#      nessie.hadoop.fs.s3a.secret.key: ${AWS_SECRET_KEY:}
#      nessie.hadoop.fs.s3a.endpoint: ${AWS_S3_ENDPOINT:s3.ap-south-1.amazonaws.com}
#      nessie.hadoop.fs.s3a.impl: org.apache.hadoop.fs.s3a.S3AFileSystem
#      nessie.hadoop.fs.s3a.path.style.access: true  # For path-style access, useful in some S3-compatible services
#      nessie.hadoop.fs.s3a.connection.ssl.enabled: false  # Enable SSL
#      nessie.hadoop.fs.s3a.fast.upload: true  # Enable faster
