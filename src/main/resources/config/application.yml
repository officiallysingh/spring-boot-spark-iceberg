# ===================================================================
# Spring Boot configuration.
#
# This configuration will be overridden by the Spring profile you use,
# for example application-dev.yml if you use the "dev" profile.
#
# Full reference for Standard Spring Boot properties is available at:
# http://docs.spring.io/spring-boot/docs/current/reference/html/common-application-properties.html
# ===================================================================
# set -Dspring.profiles.active=<dev|sit|int> as JVM argument to run in desired profile
# If no profile is specified explicitly, application will fall back to default profile, which is "local"

spring:
  application:
    name: spring-boot-spark-iceberg
  profiles:
    include:
      - ${CATALOG_TYPE:none}-catalog
      - ${STORAGE_TYPE:hadoop}-storage
  docker:
    compose:
      enabled: false
#  autoconfigure:
#    exclude: org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration
  devtools:
    add-properties: false
    restart:
      enabled: false
      exclude: logs/*,application.log,*.log,*.log.*
  main:
    log-startup-info: true
  messages:
    basename: messages,i18n/problems
    cache-duration: PT10S # 10 second, see the ISO 8601 standard
    fallback-to-system-locale: true
    always-use-message-format: false
    use-code-as-default-message: false
  mvc:
    pathmatch:
      matching-strategy: ant-path-matcher
    problemdetails:
      enabled: false
  threads:
    virtual:
      enabled: true

  jackson:
    serialization:
      write-dates-as-timestamps: false

#------------------------- Swagger configuration -------------------------
springdoc:
  show-actuator: true
  swagger-ui:
    syntaxHighlight:
      activated: true

# ------------------------ Problem configurations  ------------------------
problem:
  type-url: http://localhost:${server.port}/problems/help.html
  enabled: true
  debug-enabled: false
  stacktrace-enabled: false
  cause-chains-enabled: false

server:
  port: 8090
  forward-headers-strategy: framework
#  servlet:
#      context-path:
logging:
  level:
    ROOT: info
#    '[org.mongodb.driver]': warn
debug: false

# ===================================================================
# Application specific properties
# Add your own application properties here
# ===================================================================

#------------------------- Spark configurations -------------------------
spark:
  master: local
  app.name: ${spring.application.name}
  local.dir: spark-space/tmp
  driver:
    memory: 4g
    cores: 4
  executor:
    instances: 4
    memory: 2g
    cores: 2
  ui:
    enabled: false
  default:
    parallelism: 32
  sql:
    datetime.java8API.enabled: true
    session.timeZone: "+05:30"

#----------------- Iceberg Catalog configurations ----------------
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
#  Add VM Argument -DCATALOG_TYPE=hadoop to activate this profile   #
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
---
spring.config.activate.on-profile: hadoop-catalog
#----------------- Hadoop Iceberg Catalog configurations ----------------
spark:
  sql:
    catalog:
      hadoop: org.apache.iceberg.spark.SparkCatalog
      hadoop.type: hadoop
      hadoop.uri: ${CATALOG_URI:hdfs://localhost:9000}
      hadoop.default-namespace: ${CATALOG_NAMESPACE:ksoot}

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
#  Add VM Argument -DCATALOG_TYPE=hive to activate this profile   #
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
---
spring.config.activate.on-profile: hive-catalog
#---------------- Hive Iceberg Catalog configurations ----------------
spark:
  sql:
    catalog:
      hive: org.apache.iceberg.spark.SparkCatalog
      hive.type: hive
      hive.uri: ${CATALOG_URI:thrift://localhost:9083}
      hive.default-namespace: ${CATALOG_NAMESPACE:ksoot}

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
#  Add VM Argument -DCATALOG_TYPE=nessie to activate this profile   #
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
---
spring.config.activate.on-profile: nessie-catalog
#---------------- Nessie Iceberg Catalog configurations ----------------
spark:
  sql:
    catalog:
      nessie: org.apache.iceberg.spark.SparkCatalog
      nessie.type: nessie
      nessie.uri: ${CATALOG_URI:http://localhost:19120/api/v2}
      nessie.default-namespace: ${CATALOG_NAMESPACE:ksoot}
      #      nessie.ref: "main"

#----------------- Blob storage configurations ----------------
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
#  Add VM Argument -DSTORAGE_TYPE=hadoop to activate this profile   #
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
---
spring.config.activate.on-profile: hadoop-storage
#----------------- Hadoop configurations ----------------
spark:
  sql:
    catalog:
      hadoop.warehouse: ${CATALOG_WAREHOUSE:hdfs://localhost:9000/warehouse}
      hadoop.io-impl: org.apache.iceberg.hadoop.HadoopFileIO
      hive.warehouse: ${CATALOG_WAREHOUSE:/user/hive/warehouse}
      hive.io-impl: org.apache.iceberg.hadoop.HadoopFileIO
      nessie.warehouse: ${CATALOG_WAREHOUSE:hdfs://localhost:9000/warehouse}
      nessie.io-impl: org.apache.iceberg.hadoop.HadoopFileIO

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
#  Add VM Argument -DSTORAGE_TYPE=aws-s3 to activate this profile   #
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
---
spring.config.activate.on-profile: aws-s3-storage
#----------------- AWS S3 configurations ----------------
spring:
  cloud:
    aws:
      credentials:
        access-key: ${AWS_ACCESS_KEY}
        secret-key: ${AWS_SECRET_KEY}
      region:
        static: ${AWS_REGION:ap-south-1}
      s3:
        endpoint: ${AWS_S3_ENDPOINT:https://s3.ap-south-1.amazonaws.com}

spark:
  hadoop:
    fs:
      s3a:
        aws.credentials.provider: "org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider"
        access.key: ${AWS_ACCESS_KEY}
        secret.key: ${AWS_SECRET_KEY}
        endpoint: ${AWS_S3_ENDPOINT:s3.ap-south-1.amazonaws.com}
        impl: org.apache.hadoop.fs.s3a.S3AFileSystem
        path.style.access: true  # For path-style access, useful in some S3-compatible services
        connection.ssl.enabled: false  # Enable SSL
        fast.upload: true  # Enable faster uploads

  sql:
    catalog:
      hadoop.warehouse: ${CATALOG_WAREHOUSE:s3a://ksoot-iceberg/warehouse}
      hadoop.io-impl: org.apache.iceberg.aws.s3.S3FileIO
      hive.warehouse: ${CATALOG_WAREHOUSE:s3a://ksoot-iceberg/warehouse}
      hive.io-impl: org.apache.iceberg.aws.s3.S3FileIO
      nessie.warehouse: ${CATALOG_WAREHOUSE:s3a://ksoot-iceberg/warehouse}
      nessie.io-impl: org.apache.iceberg.aws.s3.S3FileIO

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
#  Add VM Argument -DSTORAGE_TYPE=gcs to activate this profile   #
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
---
spring.config.activate.on-profile: gcs-storage
#----------------- Google Cloud Storage configurations ----------------
#spark:
#  hadoop:
#    google.cloud.auth.service.account.json.keyfile: <your sa-key.json>
#  sql:
#    catalog:


# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
#  Add VM Argument -DSTORAGE_TYPE=abs to activate this profile   #
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
---
spring.config.activate.on-profile: abs-storage
#----------------- Azure Blob Storage configurations ----------------
#spark:
#  hadoop:
#
#  sql:
#    catalog:

